{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bebf0bfc",
   "metadata": {},
   "source": [
    "# Renal MRI Segmentation Inference Demo\n",
    "\n",
    "This notebook demonstrates how to load a pre-trained segmentation model and perform inference on new NIfTI files.\n",
    "\n",
    "## Overview\n",
    "1. Load a pre-trained model (with or without pre-training)\n",
    "2. Load a NIfTI image and its corresponding mask (optional, for evaluation)\n",
    "3. Preprocess the image (normalization, resizing)\n",
    "4. Run inference to get segmentation\n",
    "5. Visualize and save results\n",
    "6. Calculate evaluation metrics (if ground truth mask is provided)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128c646f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 1. Setup and Imports\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Import project modules\n",
    "from models.model_seg_gn import modelObj\n",
    "from data.data_utils import normalize, crop_or_pad_3d\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17eb06e",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "Set the paths to your model and data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7377d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 2. Configuration\n",
    "# =============================================================================\n",
    "\n",
    "# Model configuration\n",
    "model_config = {\n",
    "    'img_size_x': 256,\n",
    "    'img_size_y': 256,\n",
    "    'num_channels': 1,\n",
    "    'latent_dim': 64,\n",
    "    'num_classes': 3,  # 3 for whole kidney, 5 for cortex/medulla\n",
    "}\n",
    "\n",
    "# Path to pre-trained model weights\n",
    "model_weights_path = \"/path/to/your//weights.hdf5\"\n",
    "\n",
    "# Path to input NIfTI image\n",
    "image_path = \"/path/to/your/image.nii\"\n",
    "\n",
    "# Optional: Path to ground truth mask for evaluation\n",
    "mask_path = \"/path/to/your/mask.nii.gz\"\n",
    "\n",
    "# Output directory for results\n",
    "output_dir = \"./inference_results\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Model weights: {model_weights_path}\")\n",
    "print(f\"Input image: {image_path}\")\n",
    "print(f\"Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bcf990",
   "metadata": {},
   "source": [
    "## 3. Load Model\n",
    "\n",
    "Load the pre-trained segmentation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ded957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 3. Load Model\n",
    "# =============================================================================\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Simple config class to hold model parameters.\"\"\"\n",
    "    def __init__(self, config_dict):\n",
    "        for key, value in config_dict.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "# Create config object\n",
    "cfg = Config(model_config)\n",
    "\n",
    "# Initialize model utility\n",
    "print(\"Initializing model...\")\n",
    "mm_utils = modelObj(cfg)\n",
    "\n",
    "# Create segmentation model\n",
    "model = mm_utils.seg_unet(num_classes=cfg.num_classes)\n",
    "\n",
    "# Load weights\n",
    "if os.path.exists(model_weights_path):\n",
    "    print(f\"Loading weights from: {model_weights_path}\")\n",
    "    model.load_weights(model_weights_path)\n",
    "    print(\"✓ Model loaded successfully\")\n",
    "else:\n",
    "    print(f\"✗ Model weights not found at: {model_weights_path}\")\n",
    "    \n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9da2d2",
   "metadata": {},
   "source": [
    "## 4. Load and Preprocess Image\n",
    "\n",
    "Load the NIfTI image and preprocess it for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f374f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 4. Load and Preprocess Image\n",
    "# =============================================================================\n",
    "\n",
    "def load_and_preprocess_image(image_path, target_size=(256, 256)):\n",
    "    \"\"\"\n",
    "    Load NIfTI image and preprocess for inference.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to NIfTI file\n",
    "        target_size: Target (height, width) for resizing\n",
    "    \n",
    "    Returns:\n",
    "        preprocessed image array and original image info\n",
    "    \"\"\"\n",
    "    # Load NIfTI\n",
    "    nii_img = nib.load(image_path)\n",
    "    img_data = nii_img.get_fdata()\n",
    "    \n",
    "    # Get original shape and affine for later\n",
    "    original_shape = img_data.shape\n",
    "    original_affine = nii_img.affine\n",
    "    \n",
    "    print(f\"Original image shape: {original_shape}\")\n",
    "    print(f\"Image dimensions: {img_data.ndim}D\")\n",
    "    \n",
    "    # Apply same preprocessing as during training\n",
    "    # Flip and rotate to match training orientation\n",
    "    img_data = np.flip(np.rot90(img_data, -1), 1)\n",
    "    \n",
    "    # Handle different dimensionalities\n",
    "    if img_data.ndim == 3:\n",
    "        # Single channel: (H, W, D)\n",
    "        img_data = np.transpose(img_data, (2, 0, 1))  # (D, H, W)\n",
    "    elif img_data.ndim == 4:\n",
    "        # Multi-channel: (H, W, D, C)\n",
    "        img_data = np.transpose(img_data, (2, 0, 1, 3))  # (D, H, W, C)\n",
    "    \n",
    "    # Crop or pad to target size\n",
    "    processed_slices = []\n",
    "    for slice_idx in range(img_data.shape[0]):\n",
    "        if img_data.ndim == 3:\n",
    "            slice_data = img_data[slice_idx]\n",
    "        else:\n",
    "            slice_data = img_data[slice_idx, ..., 0]  # Take first channel\n",
    "        \n",
    "        # Crop/pad to target size\n",
    "        if slice_data.shape[0] != target_size[0] or slice_data.shape[1] != target_size[1]:\n",
    "            slice_data = crop_or_pad_3d(slice_data[..., np.newaxis], target_size)\n",
    "            slice_data = slice_data[..., 0]\n",
    "        \n",
    "        # Normalize\n",
    "        slice_data = normalize(slice_data)\n",
    "        processed_slices.append(slice_data)\n",
    "    \n",
    "    # Stack back\n",
    "    if img_data.ndim == 3:\n",
    "        processed_img = np.stack(processed_slices, axis=0)\n",
    "    else:\n",
    "        processed_img = np.stack(processed_slices, axis=0)[..., np.newaxis]\n",
    "    \n",
    "    print(f\"Processed image shape: {processed_img.shape}\")\n",
    "    \n",
    "    return processed_img, original_shape, original_affine\n",
    "\n",
    "# Load and preprocess image\n",
    "try:\n",
    "    img_processed, original_shape, original_affine = load_and_preprocess_image(image_path)\n",
    "    print(\"✓ Image loaded and preprocessed successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error loading image: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b307753",
   "metadata": {},
   "source": [
    "## 5. Run Inference\n",
    "\n",
    "Run the model on the preprocessed image to get segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cebcf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 5. Run Inference\n",
    "# =============================================================================\n",
    "\n",
    "def run_inference(model, image, batch_size=8):\n",
    "    \"\"\"\n",
    "    Run inference on a 3D image slice by slice.\n",
    "    \n",
    "    Args:\n",
    "        model: Keras model\n",
    "        image: Preprocessed image array (D, H, W) or (D, H, W, C)\n",
    "        batch_size: Batch size for inference\n",
    "    \n",
    "    Returns:\n",
    "        Segmentation mask (D, H, W)\n",
    "    \"\"\"\n",
    "    num_slices = image.shape[0]\n",
    "    \n",
    "    # Add channel dimension if needed\n",
    "    if image.ndim == 3:\n",
    "        image = image[..., np.newaxis]\n",
    "    \n",
    "    # Run inference in batches\n",
    "    predictions = []\n",
    "    for i in range(0, num_slices, batch_size):\n",
    "        batch = image[i:i+batch_size]\n",
    "        pred = model.predict(batch, verbose=0)\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    # Concatenate predictions\n",
    "    segmentation = np.concatenate(predictions, axis=0)\n",
    "    \n",
    "    # Convert from one-hot to class indices\n",
    "    segmentation = np.argmax(segmentation, axis=-1)\n",
    "    \n",
    "    return segmentation\n",
    "\n",
    "print(\"Running inference...\")\n",
    "segmentation = run_inference(model, img_processed)\n",
    "print(f\"✓ Inference complete. Segmentation shape: {segmentation.shape}\")\n",
    "print(f\"Unique classes: {np.unique(segmentation)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca391a6",
   "metadata": {},
   "source": [
    "## 6. Load Ground Truth \n",
    "\n",
    "If a ground truth mask is provided, load it for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ade121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 6. Load Ground Truth (Optional)\n",
    "# =============================================================================\n",
    "\n",
    "def load_ground_truth(mask_path, original_shape):\n",
    "    \"\"\"\n",
    "    Load ground truth mask and preprocess for comparison.\n",
    "    \n",
    "    Args:\n",
    "        mask_path: Path to ground truth mask\n",
    "        original_shape: Original image shape for reference\n",
    "    \n",
    "    Returns:\n",
    "        Ground truth mask array\n",
    "    \"\"\"\n",
    "    if not os.path.exists(mask_path):\n",
    "        return None\n",
    "    \n",
    "    # Load mask\n",
    "    mask_nii = nib.load(mask_path)\n",
    "    mask_data = mask_nii.get_fdata()\n",
    "    \n",
    "    # Apply same preprocessing\n",
    "    mask_data = np.flip(np.rot90(mask_data, -1), 1)\n",
    "    mask_data = np.transpose(mask_data, (2, 0, 1))\n",
    "    \n",
    "    return mask_data\n",
    "\n",
    "# Load ground truth if available\n",
    "ground_truth = None\n",
    "if mask_path and os.path.exists(mask_path):\n",
    "    ground_truth = load_ground_truth(mask_path, original_shape)\n",
    "    print(f\"✓ Ground truth loaded. Shape: {ground_truth.shape}\")\n",
    "else:\n",
    "    print(\"No ground truth mask provided or file not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9c9b00",
   "metadata": {},
   "source": [
    "## 7. Calculate Metrics \n",
    "\n",
    "If ground truth is available, calculate Dice scores and other metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae36a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 7. Calculate Metrics (Optional)\n",
    "# =============================================================================\n",
    "\n",
    "def calculate_dice_score(pred, gt, class_idx, smooth=1e-6):\n",
    "    \"\"\"\n",
    "    Calculate Dice score for a specific class.\n",
    "    \n",
    "    Args:\n",
    "        pred: Prediction mask\n",
    "        gt: Ground truth mask\n",
    "        class_idx: Class index to calculate Dice for\n",
    "        smooth: Smoothing factor\n",
    "    \n",
    "    Returns:\n",
    "        Dice score\n",
    "    \"\"\"\n",
    "    pred_class = (pred == class_idx).astype(np.float32)\n",
    "    gt_class = (gt == class_idx).astype(np.float32)\n",
    "    \n",
    "    intersection = np.sum(pred_class * gt_class)\n",
    "    union = np.sum(pred_class) + np.sum(gt_class)\n",
    "    \n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return dice\n",
    "\n",
    "if ground_truth is not None:\n",
    "    print(\"\\n=== Segmentation Metrics ===\")\n",
    "    \n",
    "    # Class names based on number of classes\n",
    "    if cfg.num_classes == 3:\n",
    "        class_names = ['Background', 'Right Kidney', 'Left Kidney']\n",
    "    else:\n",
    "        class_names = ['Background', 'Right Cortex', 'Left Cortex', \n",
    "                       'Right Medulla', 'Left Medulla']\n",
    "    \n",
    "    # Calculate Dice for each class\n",
    "    dice_scores = {}\n",
    "    for class_idx in range(1, cfg.num_classes):  # Skip background\n",
    "        dice = calculate_dice_score(segmentation, ground_truth, class_idx)\n",
    "        dice_scores[class_names[class_idx]] = dice\n",
    "        print(f\"{class_names[class_idx]}: {dice:.4f}\")\n",
    "    \n",
    "    # Calculate mean Dice (excluding background)\n",
    "    mean_dice = np.mean(list(dice_scores.values()))\n",
    "    print(f\"\\nMean Dice (excluding background): {mean_dice:.4f}\")\n",
    "else:\n",
    "    print(\"No ground truth available for metric calculation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063bf2ee",
   "metadata": {},
   "source": [
    "## 8. Visualize Results\n",
    "\n",
    "Visualize the segmentation results on sample slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6aa3b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 8. Visualize Results\n",
    "# =============================================================================\n",
    "\n",
    "def visualize_segmentation(image, segmentation, ground_truth=None, num_slices=5, save_path=None):\n",
    "    \"\"\"\n",
    "    Visualize segmentation results on sample slices.\n",
    "    \n",
    "    Args:\n",
    "        image: Original image (D, H, W)\n",
    "        segmentation: Predicted segmentation (D, H, W)\n",
    "        ground_truth: Optional ground truth mask\n",
    "        num_slices: Number of slices to display\n",
    "        save_path: Path to save figure\n",
    "    \"\"\"\n",
    "    # Select evenly spaced slices\n",
    "    total_slices = image.shape[0]\n",
    "    slice_indices = np.linspace(0, total_slices-1, num_slices, dtype=int)\n",
    "    \n",
    "    # Create colormap for segmentation\n",
    "    if cfg.num_classes == 3:\n",
    "        colors = ['black', 'red', 'blue']  # BG, Right, Left\n",
    "    else:\n",
    "        colors = ['black', 'red', 'blue', 'yellow', 'green']\n",
    "    \n",
    "    # Create figure\n",
    "    if ground_truth is not None:\n",
    "        fig, axes = plt.subplots(num_slices, 3, figsize=(15, 4*num_slices))\n",
    "    else:\n",
    "        fig, axes = plt.subplots(num_slices, 2, figsize=(12, 4*num_slices))\n",
    "    \n",
    "    # Handle single slice case\n",
    "    if num_slices == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i, slice_idx in enumerate(slice_indices):\n",
    "        # Original image\n",
    "        axes[i, 0].imshow(image[slice_idx], cmap='gray')\n",
    "        axes[i, 0].set_title(f'Original Image - Slice {slice_idx}')\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # Overlay segmentation on image\n",
    "        axes[i, 1].imshow(image[slice_idx], cmap='gray')\n",
    "        seg_overlay = np.ma.masked_where(segmentation[slice_idx] == 0, segmentation[slice_idx])\n",
    "        axes[i, 1].imshow(seg_overlay, cmap='tab10', alpha=0.5, vmin=0, vmax=cfg.num_classes-1)\n",
    "        axes[i, 1].set_title(f'Predicted Segmentation - Slice {slice_idx}')\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        # Ground truth if available\n",
    "        if ground_truth is not None:\n",
    "            axes[i, 2].imshow(image[slice_idx], cmap='gray')\n",
    "            gt_overlay = np.ma.masked_where(ground_truth[slice_idx] == 0, ground_truth[slice_idx])\n",
    "            axes[i, 2].imshow(gt_overlay, cmap='tab10', alpha=0.5, vmin=0, vmax=cfg.num_classes-1)\n",
    "            axes[i, 2].set_title(f'Ground Truth - Slice {slice_idx}')\n",
    "            axes[i, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"Figure saved to: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Visualize results\n",
    "print(\"Visualizing segmentation results...\")\n",
    "visualize_segmentation(\n",
    "    img_processed if img_processed.ndim == 3 else img_processed[..., 0],\n",
    "    segmentation,\n",
    "    ground_truth,\n",
    "    num_slices=min(5, img_processed.shape[0]),\n",
    "    save_path=os.path.join(output_dir, 'segmentation_visualization.png')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509ea8be",
   "metadata": {},
   "source": [
    "## 9. Save Segmentation Mask\n",
    "\n",
    "Save the segmentation mask as a NIfTI file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275ce9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 9. Save Segmentation Mask\n",
    "# =============================================================================\n",
    "\n",
    "def save_segmentation_mask(segmentation, original_affine, output_path):\n",
    "    \"\"\"\n",
    "    Save segmentation mask as NIfTI file.\n",
    "    \n",
    "    Args:\n",
    "        segmentation: Segmentation mask (D, H, W)\n",
    "        original_affine: Original affine transformation\n",
    "        output_path: Path to save NIfTI file\n",
    "    \"\"\"\n",
    "    # Transpose back to original orientation\n",
    "    segmentation = np.transpose(segmentation, (1, 2, 0))\n",
    "    segmentation = np.flip(np.rot90(segmentation, 1), 0)\n",
    "    \n",
    "    # Create NIfTI image\n",
    "    nii_img = nib.Nifti1Image(segmentation.astype(np.int16), original_affine)\n",
    "    nib.save(nii_img, output_path)\n",
    "    print(f\"Segmentation mask saved to: {output_path}\")\n",
    "\n",
    "# Save segmentation mask\n",
    "output_mask_path = os.path.join(output_dir, 'segmentation_mask.nii.gz')\n",
    "save_segmentation_mask(segmentation, original_affine, output_mask_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd2386b",
   "metadata": {},
   "source": [
    "## 10. Batch Processing \n",
    "\n",
    "Process multiple images in a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055a03b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 10. Batch Processing (Optional)\n",
    "# =============================================================================\n",
    "\n",
    "def batch_process_directory(input_dir, output_dir, model, file_pattern=\"*.nii*\"):\n",
    "    \"\"\"\n",
    "    Process all NIfTI files in a directory.\n",
    "    \n",
    "    Args:\n",
    "        input_dir: Input directory containing NIfTI files\n",
    "        output_dir: Output directory for segmentation masks\n",
    "        model: Keras model\n",
    "        file_pattern: Pattern to match NIfTI files\n",
    "    \"\"\"\n",
    "    import glob\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    nifti_files = glob.glob(os.path.join(input_dir, file_pattern))\n",
    "    \n",
    "    print(f\"Found {len(nifti_files)} NIfTI files to process\")\n",
    "    \n",
    "    for i, file_path in enumerate(nifti_files):\n",
    "        print(f\"\\nProcessing [{i+1}/{len(nifti_files)}]: {os.path.basename(file_path)}\")\n",
    "        \n",
    "        try:\n",
    "            # Load and preprocess\n",
    "            img_processed, _, original_affine = load_and_preprocess_image(file_path)\n",
    "            \n",
    "            # Run inference\n",
    "            segmentation = run_inference(model, img_processed)\n",
    "            \n",
    "            # Save result\n",
    "            output_filename = os.path.basename(file_path).replace('.nii', '_seg.nii')\n",
    "            output_path = os.path.join(output_dir, output_filename)\n",
    "            \n",
    "            # Transpose back\n",
    "            seg_to_save = np.transpose(segmentation, (1, 2, 0))\n",
    "            seg_to_save = np.flip(np.rot90(seg_to_save, 1), 0)\n",
    "            \n",
    "            # Save\n",
    "            nii_img = nib.Nifti1Image(seg_to_save.astype(np.int16), original_affine)\n",
    "            nib.save(nii_img, output_path)\n",
    "            \n",
    "            print(f\"✓ Saved: {output_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"✗ Error processing {file_path}: {e}\")\n",
    "\n",
    "# Uncomment to run batch processing\n",
    "# input_directory = \"/path/to/your/images\"\n",
    "# batch_output_dir = os.path.join(output_dir, \"batch_results\")\n",
    "# batch_process_directory(input_directory, batch_output_dir, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55094948",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. Loading a pre-trained segmentation model\n",
    "2. Preprocessing a NIfTI image for inference\n",
    "3. Running slice-by-slice inference\n",
    "4. Visualizing segmentation results\n",
    "5. Calculating evaluation metrics (if ground truth available)\n",
    "6. Saving segmentation masks as NIfTI files\n",
    "\n",
    "The saved segmentation mask can be found at: `{output_dir}/segmentation_mask.nii.gz`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
